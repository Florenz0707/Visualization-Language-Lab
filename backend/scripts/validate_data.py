"""
æ•°æ®å®Œæ•´æ€§éªŒè¯è„šæœ¬
æ£€æŸ¥é¡¹ç›®æ‰€éœ€çš„æ‰€æœ‰åœ°ç†æ•°æ®æ˜¯å¦å·²æ­£ç¡®ä¸‹è½½å’Œå¤„ç†
åŒ…æ‹¬ï¼šGeoJSONæ–‡ä»¶ã€DEMæ•°æ®ã€å†å²åœ°å›¾ç­‰
"""

import json
from pathlib import Path
from typing import Dict, List, Tuple
import sys


# ç›®å½•é…ç½®
DATA_DIR = Path(__file__).parent.parent / "data"
GEOJSON_DIR = DATA_DIR / "geojson"
DEM_DIR = DATA_DIR / "dem"
BOUNDARIES_DIR = DATA_DIR / "boundaries"
MAPS_DIR = DATA_DIR / "historical_maps"


class DataValidator:
    """æ•°æ®éªŒè¯å™¨"""

    def __init__(self):
        self.results = {
            'passed': [],
            'failed': [],
            'warnings': []
        }

    def check_geojson_file(self, filepath: Path, name: str, required: bool = True) -> bool:
        """
        éªŒè¯GeoJSONæ–‡ä»¶

        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            name: æ˜¾ç¤ºåç§°
            required: æ˜¯å¦å¿…éœ€

        Returns:
            éªŒè¯æ˜¯å¦é€šè¿‡
        """
        if not filepath.exists():
            msg = f"{name}: æ–‡ä»¶ä¸å­˜åœ¨ ({filepath.name})"
            if required:
                self.results['failed'].append(msg)
                print(f"âŒ {msg}")
                return False
            else:
                self.results['warnings'].append(msg)
                print(f"âš ï¸  {msg}")
                return False

        try:
            # è¯»å–GeoJSON
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            if data.get('type') not in ['FeatureCollection', 'Feature']:
                self.results['failed'].append(f"{name}: æ— æ•ˆçš„GeoJSONç±»å‹")
                print(f"âŒ {name}: æ— æ•ˆçš„GeoJSONç±»å‹")
                return False

            # è·å–ç‰¹å¾æ•°é‡
            if data['type'] == 'FeatureCollection':
                feature_count = len(data.get('features', []))
            else:
                feature_count = 1

            # è·å–æ–‡ä»¶å¤§å°
            size_mb = filepath.stat().st_size / (1024 * 1024)

            msg = f"{name}: {filepath.name} ({feature_count} ä¸ªç‰¹å¾, {size_mb:.2f} MB)"
            self.results['passed'].append(msg)
            print(f"âœ… {msg}")
            return True

        except json.JSONDecodeError as e:
            msg = f"{name}: JSONæ ¼å¼é”™è¯¯ - {str(e)}"
            self.results['failed'].append(msg)
            print(f"âŒ {msg}")
            return False
        except Exception as e:
            msg = f"{name}: éªŒè¯å‡ºé”™ - {str(e)}"
            self.results['failed'].append(msg)
            print(f"âŒ {msg}")
            return False

    def check_shapefile_dataset(self, directory: Path, name: str) -> bool:
        """
        éªŒè¯Shapefileæ•°æ®é›†ï¼ˆæ£€æŸ¥.shp, .shx, .dbfæ–‡ä»¶ï¼‰

        Args:
            directory: æ•°æ®é›†ç›®å½•
            name: æ˜¾ç¤ºåç§°

        Returns:
            éªŒè¯æ˜¯å¦é€šè¿‡
        """
        if not directory.exists():
            msg = f"{name}: ç›®å½•ä¸å­˜åœ¨"
            self.results['warnings'].append(msg)
            print(f"âš ï¸  {msg}")
            return False

        # æŸ¥æ‰¾.shpæ–‡ä»¶
        shp_files = list(directory.glob("*.shp"))

        if not shp_files:
            msg = f"{name}: æœªæ‰¾åˆ°Shapefile"
            self.results['warnings'].append(msg)
            print(f"âš ï¸  {msg}")
            return False

        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        shp_file = shp_files[0]
        stem = shp_file.stem
        required_extensions = ['.shp', '.shx', '.dbf']

        missing = []
        for ext in required_extensions:
            if not (directory / f"{stem}{ext}").exists():
                missing.append(ext)

        if missing:
            msg = f"{name}: ç¼ºå°‘æ–‡ä»¶ {', '.join(missing)}"
            self.results['failed'].append(msg)
            print(f"âŒ {msg}")
            return False

        # è®¡ç®—ç›®å½•å¤§å°
        total_size = sum(f.stat().st_size for f in directory.rglob("*") if f.is_file())
        size_mb = total_size / (1024 * 1024)

        msg = f"{name}: {directory.name} ({size_mb:.2f} MB)"
        self.results['passed'].append(msg)
        print(f"âœ… {msg}")
        return True

    def check_dem_data(self) -> Tuple[int, float]:
        """
        æ£€æŸ¥DEMæ•°æ®

        Returns:
            (ç“¦ç‰‡æ•°é‡, æ€»å¤§å°MB)
        """
        jaxa_dir = DEM_DIR / "jaxa_aw3d30"

        if not jaxa_dir.exists():
            msg = "DEMæ•°æ®: jaxa_aw3d30ç›®å½•ä¸å­˜åœ¨"
            self.results['warnings'].append(msg)
            print(f"âš ï¸  {msg}")
            return 0, 0.0

        # æŸ¥æ‰¾æ‰€æœ‰.tifæ–‡ä»¶
        tif_files = list(jaxa_dir.rglob("*.tif"))

        if not tif_files:
            msg = "DEMæ•°æ®: æœªæ‰¾åˆ°TIFFæ–‡ä»¶"
            self.results['warnings'].append(msg)
            print(f"âš ï¸  {msg}")
            return 0, 0.0

        # è®¡ç®—æ€»å¤§å°
        total_size = sum(f.stat().st_size for f in tif_files)
        size_mb = total_size / (1024 * 1024)

        # ç»Ÿè®¡ZIPæ–‡ä»¶ï¼ˆåŸå§‹ä¸‹è½½ï¼‰
        zip_files = list(jaxa_dir.glob("*.zip"))

        msg = f"DEMæ•°æ®: {len(tif_files)} ä¸ªTIFFæ–‡ä»¶"
        if zip_files:
            msg += f", {len(zip_files)} ä¸ªZIPæ–‡ä»¶"
        msg += f" ({size_mb:.2f} MB)"

        self.results['passed'].append(msg)
        print(f"âœ… {msg}")
        return len(tif_files), size_mb

    def check_processed_dem(self) -> bool:
        """æ£€æŸ¥å¤„ç†åçš„DEMæ•°æ®"""
        processed_dir = DEM_DIR / "processed"

        if not processed_dir.exists():
            msg = "å¤„ç†åDEM: ç›®å½•ä¸å­˜åœ¨ï¼ˆå¯é€‰ï¼‰"
            self.results['warnings'].append(msg)
            print(f"âš ï¸  {msg}")
            return False

        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        files_to_check = {
            'merged_dem.tif': 'åˆå¹¶çš„DEM',
            'heightmap.png': 'é«˜ç¨‹è´´å›¾',
            'hillshade.tif': 'å±±ä½“é˜´å½±'
        }

        found_files = []
        for filename, description in files_to_check.items():
            filepath = processed_dir / filename
            if filepath.exists():
                size_mb = filepath.stat().st_size / (1024 * 1024)
                found_files.append(f"{description} ({size_mb:.2f} MB)")

        if found_files:
            msg = f"å¤„ç†åDEM: {', '.join(found_files)}"
            self.results['passed'].append(msg)
            print(f"âœ… {msg}")
            return True
        else:
            msg = "å¤„ç†åDEM: æœªæ‰¾åˆ°å¤„ç†æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰"
            self.results['warnings'].append(msg)
            print(f"âš ï¸  {msg}")
            return False

    def check_historical_maps(self) -> bool:
        """æ£€æŸ¥å†å²åœ°å›¾"""
        if not MAPS_DIR.exists():
            msg = "å†å²åœ°å›¾: ç›®å½•ä¸å­˜åœ¨"
            self.results['warnings'].append(msg)
            print(f"âš ï¸  {msg}")
            return False

        # æ£€æŸ¥Minardå›¾
        minard_path = MAPS_DIR / "Minard.png"
        if minard_path.exists():
            size_mb = minard_path.stat().st_size / (1024 * 1024)
            msg = f"å†å²åœ°å›¾: Minard.png ({size_mb:.2f} MB)"
            self.results['passed'].append(msg)
            print(f"âœ… {msg}")
            return True
        else:
            msg = "å†å²åœ°å›¾: Minard.png æœªæ‰¾åˆ°"
            self.results['warnings'].append(msg)
            print(f"âš ï¸  {msg}")
            return False


def print_section_header(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f"{title}")
    print(f"{'='*60}\n")


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("æ•°æ®å®Œæ•´æ€§éªŒè¯")
    print("1812æ‹¿ç ´ä»‘ä¸œå¾åœ°ç†å¯è§†åŒ–é¡¹ç›®")
    print("="*60)

    validator = DataValidator()

    # 1. éªŒè¯GeoJSONæ–‡ä»¶
    print_section_header("ğŸ“ GeoJSONæ•°æ®éªŒè¯")

    geojson_files = [
        (GEOJSON_DIR / "events.geojson", "å†å²äº‹ä»¶", True),
        (GEOJSON_DIR / "countries.geojson", "å›½å®¶è¾¹ç•Œ", True),
        (GEOJSON_DIR / "provinces.geojson", "çœä»½è¾¹ç•Œ", False),
        (GEOJSON_DIR / "cities.geojson", "ä¸»è¦åŸå¸‚", True),
        (GEOJSON_DIR / "rivers.geojson", "æ²³æµæ¹–æ³Š", True),
        (GEOJSON_DIR / "movements.geojson", "å†›é˜Ÿç§»åŠ¨è½¨è¿¹", True),
        (GEOJSON_DIR / "territories.geojson", "é¢†åœŸå˜åŒ–", False),
        (GEOJSON_DIR / "cities_major.geojson", "å¤§åŸå¸‚ï¼ˆè¿‡æ»¤ï¼‰", False),
        (GEOJSON_DIR / "cities_1812_campaign.geojson", "ä¸œå¾ç›¸å…³åŸå¸‚", False),
        (GEOJSON_DIR / "countries_eastern_europe.geojson", "ä¸œæ¬§å›½å®¶ï¼ˆè¿‡æ»¤ï¼‰", False),
    ]

    for filepath, name, required in geojson_files:
        validator.check_geojson_file(filepath, name, required)

    # 2. éªŒè¯ShapefileåŸå§‹æ•°æ®
    print_section_header("ğŸ—ºï¸  ShapefileåŸå§‹æ•°æ®éªŒè¯")

    shapefile_datasets = [
        (BOUNDARIES_DIR / "ne_10m_admin_0_countries", "å›½å®¶è¾¹ç•Œ Shapefile"),
        (BOUNDARIES_DIR / "ne_10m_admin_1_states_provinces", "çœä»½è¾¹ç•Œ Shapefile"),
        (BOUNDARIES_DIR / "ne_10m_populated_places", "åŸå¸‚ç‚¹ Shapefile"),
        (BOUNDARIES_DIR / "ne_10m_rivers_lake_centerlines", "æ²³æµçº¿ Shapefile"),
    ]

    for directory, name in shapefile_datasets:
        validator.check_shapefile_dataset(directory, name)

    # 3. éªŒè¯DEMæ•°æ®
    print_section_header("ğŸ”ï¸  DEMé«˜ç¨‹æ•°æ®éªŒè¯")

    tif_count, dem_size = validator.check_dem_data()
    validator.check_processed_dem()

    # æ£€æŸ¥ç­‰é«˜çº¿
    contours_path = DEM_DIR / "contours.geojson"
    validator.check_geojson_file(contours_path, "ç­‰é«˜çº¿", required=False)

    # 4. éªŒè¯å†å²åœ°å›¾
    print_section_header("ğŸ–¼ï¸  å†å²åœ°å›¾éªŒè¯")

    validator.check_historical_maps()

    # 5. æ€»ç»“æŠ¥å‘Š
    print_section_header("ğŸ“Š éªŒè¯æ€»ç»“")

    passed_count = len(validator.results['passed'])
    failed_count = len(validator.results['failed'])
    warning_count = len(validator.results['warnings'])

    print(f"âœ… é€šè¿‡: {passed_count} é¡¹")
    print(f"âŒ å¤±è´¥: {failed_count} é¡¹")
    print(f"âš ï¸  è­¦å‘Š: {warning_count} é¡¹")

    # è¯¦ç»†åˆ—è¡¨
    if validator.results['failed']:
        print("\nâŒ å¤±è´¥é¡¹ç›®:")
        for msg in validator.results['failed']:
            print(f"   - {msg}")

    if validator.results['warnings']:
        print("\nâš ï¸  è­¦å‘Šé¡¹ç›®:")
        for msg in validator.results['warnings']:
            print(f"   - {msg}")

    # é¡¹ç›®å°±ç»ªçŠ¶æ€
    print("\n" + "="*60)

    # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
    required_files = [
        GEOJSON_DIR / "events.geojson",
        GEOJSON_DIR / "countries.geojson",
        GEOJSON_DIR / "cities.geojson",
        GEOJSON_DIR / "rivers.geojson",
    ]

    all_required_exist = all(f.exists() for f in required_files)
    has_dem = tif_count > 0

    if all_required_exist and has_dem:
        print("ğŸ‰ é¡¹ç›®æ•°æ®å·²å°±ç»ªï¼å¯ä»¥å¼€å§‹å¼€å‘ã€‚")
        print("\nå»ºè®®:")
        print("  1. å¦‚æœç¼ºå°‘ movements.geojsonï¼Œéœ€è¦æ‰‹åŠ¨åˆ›å»ºå†›é˜Ÿç§»åŠ¨è½¨è¿¹")
        print("  2. å¯é€‰ï¼šè¿è¡Œ process_dem.py å¤„ç†DEMæ•°æ®ç”Ÿæˆé«˜ç¨‹è´´å›¾")
        print("  3. å¯é€‰ï¼šä¸‹è½½æ›´å¤šå†å²åœ°å›¾åˆ° data/historical_maps/story/")
        return_code = 0
    elif all_required_exist:
        print("âš ï¸  åŸºç¡€GeoJSONæ–‡ä»¶å·²å°±ç»ªï¼Œä½†ç¼ºå°‘DEMæ•°æ®")
        print("\nå»ºè®®:")
        print("  1. è¿è¡Œ download_jaxa_aw3d30.py ä¸‹è½½DEMæ•°æ®")
        print("  2. åˆ›å»º movements.geojson å†›é˜Ÿç§»åŠ¨è½¨è¿¹")
        return_code = 1
    else:
        print("âŒ é¡¹ç›®æ•°æ®ä¸å®Œæ•´ï¼Œæ— æ³•å¼€å§‹å¼€å‘")
        print("\nå»ºè®®:")
        print("  1. è¿è¡Œ download_geodata.py ä¸‹è½½è¡Œæ”¿åŒºåˆ’æ•°æ®")
        print("  2. è¿è¡Œ convert_shapefiles_to_geojson.py è½¬æ¢GeoJSON")
        print("  3. è¿è¡Œ download_jaxa_aw3d30.py ä¸‹è½½DEMæ•°æ®")
        print("  4. åˆ›å»º movements.geojson å†›é˜Ÿç§»åŠ¨è½¨è¿¹")
        return_code = 2

    print("="*60)

    sys.exit(return_code)


if __name__ == "__main__":
    main()
